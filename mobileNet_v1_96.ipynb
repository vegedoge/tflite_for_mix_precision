{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2186e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "068e6f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 版本: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorFlow 版本: {tf.__version__}\")\n",
    "\n",
    "INPUT_SHAPE = (96, 96, 3) # <--- 修改点\n",
    "NUM_CLASSES = 10           # 假的分类头，10类 (数字不重要\n",
    "MODEL_ALPHA = 0.25          # 宽度系数 \n",
    "\n",
    "# --- 1. 定义模型和保存路径 ---\n",
    "MODEL_DIR = f\"models_mobilenet_v1_{INPUT_SHAPE[0]}\"\n",
    "FP32_SAVED_MODEL_PATH = os.path.join(MODEL_DIR, f\"mobilenet_v1_{INPUT_SHAPE[0]}_fp32_savedmodel\")\n",
    "TFLITE_INT8_MODEL_PATH = os.path.join(MODEL_DIR, f\"mobilenet_v1_{INPUT_SHAPE[0]}_int8.tflite\")\n",
    "# 确保目录存在\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61b30e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 计算 SavedModel 总大小的函数 ---\n",
    "def get_savedmodel_total_size(path):\n",
    "    \"\"\"计算 SavedModel 目录的总大小\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            if os.path.isfile(filepath):\n",
    "                total_size += os.path.getsize(filepath)\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "323c903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载 FP32 MobileNetV1 - 96(ImageNet 预训练)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6886/957121652.py:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = tf.keras.applications.MobileNet(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在将 FP32 模型保存到: models_mobilenet_v1_96/mobilenet_v1_96_fp32_savedmodel\n",
      "INFO:tensorflow:Assets written to: models_mobilenet_v1_96/mobilenet_v1_96_fp32_savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models_mobilenet_v1_96/mobilenet_v1_96_fp32_savedmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'models_mobilenet_v1_96/mobilenet_v1_96_fp32_savedmodel'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='keras_tensor_352')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  125775306958096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306958288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306950608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306955792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306956752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306956944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306958480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306957904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306954832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306948688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306958864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306955984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306955408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306956560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306959440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306957328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125780027226832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306952912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125780027227024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306957520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125780027227984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125780027226256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980508752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775306951952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125780027226640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980509136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980509520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980508944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980511056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980510672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980509712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980509904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980510480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980510096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980512592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980511632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980511824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980512400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980509328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980513552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980512208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980512784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980510864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980513744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980512016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980513168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775903767056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775903768208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125775903768400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980510288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980513360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440094352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440093968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125776980512976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440096464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440094736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440096080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440094544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440096272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440097424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440096848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440096656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440095696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440093776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440098576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440097808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440097616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440097040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440094928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440099536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440098960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440098768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440098192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440095888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440100304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440099728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440098000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440099152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440097232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440101264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440100688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440100496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440099920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440098384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440102224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440101648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440101456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440100880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440099344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440103184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440102608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440102416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440101840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440100112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440104144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440103568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440103376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440102800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440101072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440105104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440104528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440104336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440103760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440102032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440106064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440105488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440105296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440104720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440102992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440107024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440106448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440106256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440105680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440103952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440107984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440107408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440107216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440106640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440104912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440108944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440108368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440108176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440107600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440105872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440109520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440109328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440109136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440109712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440109904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440108752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440107792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440108560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125774706376144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440094160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125778440106832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125780836593744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  125774706374608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "FP32 模型保存完毕。\n",
      "开始执行 TFLite INT8 转换...\n",
      "正在转换... 这可能需要几分钟时间...\n",
      "模型转换成功！\n",
      "--------------------------------------------------\n",
      "恭喜！纯 INT8 TFLite 模型已生成！\n",
      "路径: models_mobilenet_v1_96/mobilenet_v1_96_int8.tflite\n",
      "FP32 SavedModel (pb文件) 大小约: 2.49 MB\n",
      "INT8 TFLite 模型大小: 0.29 MB\n",
      "(模型大小减少了约 88.3%)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1761244224.333586    6886 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1761244224.333648    6886 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-10-23 20:30:24.333820: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: models_mobilenet_v1_96/mobilenet_v1_96_fp32_savedmodel\n",
      "2025-10-23 20:30:24.337244: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-10-23 20:30:24.337271: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: models_mobilenet_v1_96/mobilenet_v1_96_fp32_savedmodel\n",
      "2025-10-23 20:30:24.375016: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-10-23 20:30:24.624976: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: models_mobilenet_v1_96/mobilenet_v1_96_fp32_savedmodel\n",
      "2025-10-23 20:30:24.690488: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 356672 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "2025-10-23 20:30:25.044633: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3705] Skipping runtime version metadata in the model. This will be generated by the exporter.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. 加载预训练的 FP32 MobileNetV1 ---\n",
    "# 我们需要一个基础模型来进行转换\n",
    "\n",
    "print(f\"正在加载 FP32 MobileNetV1 - {INPUT_SHAPE[0]}(ImageNet 预训练)...\")\n",
    "base_model = tf.keras.applications.MobileNet(\n",
    "    alpha=MODEL_ALPHA,\n",
    "    weights='imagenet', \n",
    "    include_top=False,\n",
    "    input_shape=INPUT_SHAPE,\n",
    ")\n",
    "\n",
    "# 针对96x96输入，我们需要添加一个分类头\n",
    "# 添加一个假的分类头 (因为我们只关心算子，不关心精度)\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x)\n",
    "x = tf.keras.layers.Dense(NUM_CLASSES, name=\"classifier\")(x)\n",
    "\n",
    "fp32_model = tf.keras.Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# print(\"96 x 96 model architecture:\")\n",
    "# fp32_model.summary()\n",
    "\n",
    "# 保存为 SavedModel 格式，这是 TFLiteConverter 的标准输入\n",
    "print(f\"正在将 FP32 模型保存到: {FP32_SAVED_MODEL_PATH}\")\n",
    "fp32_model.export(FP32_SAVED_MODEL_PATH)\n",
    "print(\"FP32 模型保存完毕。\")\n",
    "\n",
    "# --- 3. 创建一个“虚拟”的校准数据集 ---\n",
    "#\n",
    "# !!! 关键说明 !!!\n",
    "# 正常情况下，这里需要 100-500 张你真实场景的图片。\n",
    "# 因为你只关心算子优化，不关心精度，我们这里只使用\n",
    "# 几批随机数据来“喂饱” TFLiteConverter，让它完成 INT8 的转换。\n",
    "#\n",
    "# MobileNetV1 的 Keras 预处理是将 [0, 255] 缩放到 [-1, 1]\n",
    "# 所以我们生成这个范围内的随机数据。\n",
    "#\n",
    "\n",
    "def dummy_representative_dataset_gen():\n",
    "    # 我们只提供 10 批数据，每批 1 张图片\n",
    "    for _ in range(10):\n",
    "        # 1. 生成 [0, 1] 范围的随机数据\n",
    "        data = np.random.rand(1, *INPUT_SHAPE).astype(np.float32)\n",
    "        # 2. 缩放到 [-1, 1] 范围\n",
    "        data = (data * 2.0) - 1.0\n",
    "        # 3. yield 一个列表\n",
    "        yield [data]\n",
    "    print(\"已生成所有“虚拟”校准数据。\")\n",
    "    \n",
    "def representative_dataset_gen():\n",
    "    # 使用正确的 MobileNet 预处理：生成 [0, 255] 范围的随机数据\n",
    "    for _ in range(10):\n",
    "        # 生成 [0, 255] 范围的随机图像数据\n",
    "        data = np.random.rand(1, *INPUT_SHAPE).astype(np.float32) * 255.0\n",
    "        yield [data]\n",
    "\n",
    "\n",
    "# --- 4. 执行 INT8 转换 ---\n",
    "print(\"开始执行 TFLite INT8 转换...\")\n",
    "\n",
    "# 1. 初始化 TFLiteConverter\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(FP32_SAVED_MODEL_PATH)\n",
    "\n",
    "# 2. 开启优化 (这是INT8量化的开关)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# 3. 指定“虚拟”校准数据集\n",
    "# converter.representative_dataset = dummy_representative_dataset_gen\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "# 4. 强制要求所有算子都是 INT8\n",
    "# 这是为了确保模型在你的板子上能最大程度地使用 INT8 硬件\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # 设置输入为 INT8\n",
    "converter.inference_output_type = tf.int8 # 设置输出为 INT8\n",
    "\n",
    "# 5. 执行转换\n",
    "print(\"正在转换... 这可能需要几分钟时间...\")\n",
    "try:\n",
    "    tflite_int8_model_content = converter.convert()\n",
    "    print(\"模型转换成功！\")\n",
    "\n",
    "    # 6. 保存 INT8 TFLite 模型\n",
    "    with open(TFLITE_INT8_MODEL_PATH, \"wb\") as f:\n",
    "        f.write(tflite_int8_model_content)\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"恭喜！纯 INT8 TFLite 模型已生成！\")\n",
    "    print(f\"路径: {TFLITE_INT8_MODEL_PATH}\")\n",
    "    \n",
    "    # 比较文件大小\n",
    "    fp32_size_approx = get_savedmodel_total_size(FP32_SAVED_MODEL_PATH) / (1024*1024)\n",
    "    int8_size = os.path.getsize(TFLITE_INT8_MODEL_PATH) / (1024*1024)\n",
    "    \n",
    "    print(f\"FP32 SavedModel (pb文件) 大小约: {fp32_size_approx:.2f} MB\")\n",
    "    print(f\"INT8 TFLite 模型大小: {int8_size:.2f} MB\")\n",
    "    print(f\"(模型大小减少了约 {(1 - int8_size / fp32_size_approx) * 100:.1f}%)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"模型转换失败: {e}\")\n",
    "    print(\"请检查你的 TensorFlow 和 NumPy 版本。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf27fe75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df3710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedded_ai_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
