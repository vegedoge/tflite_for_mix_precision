{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2186e5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 19:33:38.865192: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-23 19:33:39.640491: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-23 19:33:42.007795: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e6f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 版本: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorFlow 版本: {tf.__version__}\")\n",
    "\n",
    "# --- 1. 定义模型和保存路径 ---\n",
    "MODEL_DIR = \"models_mobileNet_V1_224input\"\n",
    "FP32_SAVED_MODEL_PATH = os.path.join(MODEL_DIR, \"mobilenet_v1_fp32_savedmodel\")\n",
    "TFLITE_INT8_MODEL_PATH = os.path.join(MODEL_DIR, \"mobilenet_v1_int8.tflite\")\n",
    "\n",
    "# 确保目录存在\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b30e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 计算 SavedModel 总大小的函数 ---\n",
    "def get_savedmodel_total_size(path):\n",
    "    \"\"\"计算 SavedModel 目录的总大小\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            if os.path.isfile(filepath):\n",
    "                total_size += os.path.getsize(filepath)\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "323c903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载 FP32 MobileNetV1 (ImageNet 预训练)...\n",
      "正在将 FP32 模型保存到: models/mobilenet_v1_fp32_savedmodel\n",
      "INFO:tensorflow:Assets written to: models/mobilenet_v1_fp32_savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mobilenet_v1_fp32_savedmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'models/mobilenet_v1_fp32_savedmodel'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_182')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1000), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  123712692871312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692872080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692874768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692875152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692874576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692871504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692871696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692874960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692871888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692875920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692874384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692875728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692875344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692872272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692876880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692874000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692876112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692876688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692870928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692877840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692876496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692877072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692877648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692873616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692878800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692877456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692878032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692878608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692875536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692870736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692878416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692878992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692869968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692876304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692865168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123715631809744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692870544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692879184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123715631809360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123714699780432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692869200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692878224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692868624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692877264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692870160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123712692870352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635061456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635061264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635062416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635060880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635062032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635060496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635060304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635061648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635059920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635060112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635059536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635059344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635061072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635058960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635059152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635058576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635058384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635061840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635058000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635058192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635057616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635057424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635060688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635057040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635057232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635056656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635056464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635059728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635056080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635056272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635055696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635055504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635058768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635055120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635055312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635054736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635054544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635057808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635054160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635054352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635053776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635053584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635056848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635053200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635053392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635052816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635052624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635055888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635052240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635052432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635051856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635051664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635054928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635051280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635051472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635050896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635050704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635053968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635050320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635050512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635049936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635049744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635053008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635049360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635049552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635048976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635048784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635052048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635048400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635048592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635048016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635047824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635051088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635047440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635047632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635047056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635048208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635062608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635047248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635049168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635046672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635046480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635046864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123711635050128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123714521133136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123714521124304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123714521131792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123714521130640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123714521129872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123714521123920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  123714521131024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "FP32 模型保存完毕。\n",
      "开始执行 TFLite INT8 转换...\n",
      "正在转换... 这可能需要几分钟时间...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1761241414.358688    2256 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1761241414.358790    2256 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-10-23 19:43:34.358996: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: models/mobilenet_v1_fp32_savedmodel\n",
      "2025-10-23 19:43:34.363118: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-10-23 19:43:34.363132: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: models/mobilenet_v1_fp32_savedmodel\n",
      "2025-10-23 19:43:34.410154: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-10-23 19:43:34.656885: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: models/mobilenet_v1_fp32_savedmodel\n",
      "2025-10-23 19:43:34.712510: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 353525 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型转换成功！\n",
      "--------------------------------------------------\n",
      "恭喜！纯 INT8 TFLite 模型已生成！\n",
      "路径: models/mobilenet_v1_int8.tflite\n",
      "FP32 SavedModel (pb文件) 大小约: 33.27 MB\n",
      "INT8 TFLite 模型大小: 4.35 MB\n",
      "(模型大小减少了约 86.9%)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "2025-10-23 19:43:35.846756: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3705] Skipping runtime version metadata in the model. This will be generated by the exporter.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. 加载预训练的 FP32 MobileNetV1 ---\n",
    "# 我们需要一个基础模型来进行转换\n",
    "print(\"正在加载 FP32 MobileNetV1 (ImageNet 预训练)...\")\n",
    "fp32_model = tf.keras.applications.MobileNet(\n",
    "    weights='imagenet', \n",
    "    include_top=True, \n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# 保存为 SavedModel 格式，这是 TFLiteConverter 的标准输入\n",
    "print(f\"正在将 FP32 模型保存到: {FP32_SAVED_MODEL_PATH}\")\n",
    "fp32_model.export(FP32_SAVED_MODEL_PATH)\n",
    "print(\"FP32 模型保存完毕。\")\n",
    "\n",
    "# --- 3. 创建一个“虚拟”的校准数据集 ---\n",
    "#\n",
    "# !!! 关键说明 !!!\n",
    "# 正常情况下，这里需要 100-500 张你真实场景的图片。\n",
    "# 因为你只关心算子优化，不关心精度，我们这里只使用\n",
    "# 几批随机数据来“喂饱” TFLiteConverter，让它完成 INT8 的转换。\n",
    "#\n",
    "# MobileNetV1 的 Keras 预处理是将 [0, 255] 缩放到 [-1, 1]\n",
    "# 所以我们生成这个范围内的随机数据。\n",
    "#\n",
    "\n",
    "def dummy_representative_dataset_gen():\n",
    "    # 我们只提供 10 批数据，每批 1 张图片\n",
    "    for _ in range(10):\n",
    "        # 1. 生成 [0, 1] 范围的随机数据\n",
    "        data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n",
    "        # 2. 缩放到 [-1, 1] 范围\n",
    "        data = (data * 2.0) - 1.0\n",
    "        # 3. yield 一个列表\n",
    "        yield [data]\n",
    "    print(\"已生成所有“虚拟”校准数据。\")\n",
    "    \n",
    "def representative_dataset_gen():\n",
    "    # 使用正确的 MobileNet 预处理：生成 [0, 255] 范围的随机数据\n",
    "    for _ in range(10):\n",
    "        # 生成 [0, 255] 范围的随机图像数据\n",
    "        data = np.random.rand(1, 224, 224, 3).astype(np.float32) * 255.0\n",
    "        yield [data]\n",
    "\n",
    "\n",
    "# --- 4. 执行 INT8 转换 ---\n",
    "print(\"开始执行 TFLite INT8 转换...\")\n",
    "\n",
    "# 1. 初始化 TFLiteConverter\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(FP32_SAVED_MODEL_PATH)\n",
    "\n",
    "# 2. 开启优化 (这是INT8量化的开关)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# 3. 指定“虚拟”校准数据集\n",
    "# converter.representative_dataset = dummy_representative_dataset_gen\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "# 4. 强制要求所有算子都是 INT8\n",
    "# 这是为了确保模型在你的板子上能最大程度地使用 INT8 硬件\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # 设置输入为 INT8\n",
    "converter.inference_output_type = tf.int8 # 设置输出为 INT8\n",
    "\n",
    "# 5. 执行转换\n",
    "print(\"正在转换... 这可能需要几分钟时间...\")\n",
    "try:\n",
    "    tflite_int8_model_content = converter.convert()\n",
    "    print(\"模型转换成功！\")\n",
    "\n",
    "    # 6. 保存 INT8 TFLite 模型\n",
    "    with open(TFLITE_INT8_MODEL_PATH, \"wb\") as f:\n",
    "        f.write(tflite_int8_model_content)\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"恭喜！纯 INT8 TFLite 模型已生成！\")\n",
    "    print(f\"路径: {TFLITE_INT8_MODEL_PATH}\")\n",
    "    \n",
    "    # 比较文件大小\n",
    "    fp32_size_approx = get_savedmodel_total_size(FP32_SAVED_MODEL_PATH) / (1024*1024)\n",
    "    int8_size = os.path.getsize(TFLITE_INT8_MODEL_PATH) / (1024*1024)\n",
    "    \n",
    "    print(f\"FP32 SavedModel (pb文件) 大小约: {fp32_size_approx:.2f} MB\")\n",
    "    print(f\"INT8 TFLite 模型大小: {int8_size:.2f} MB\")\n",
    "    print(f\"(模型大小减少了约 {(1 - int8_size / fp32_size_approx) * 100:.1f}%)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"模型转换失败: {e}\")\n",
    "    print(\"请检查你的 TensorFlow 和 NumPy 版本。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df3710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66580c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedded_ai_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
